{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon examination of the results from the TimeseriesModelling file across various time windows, it was determined that testing the hypothesis that our exogenous sentiment score contains more information than other publicly available sentiment scores, as exemplified by the MCSI, is only feasible through the inclusion of lagged values of the sentiment score. In order to assess the prediction improvement, we will fit ARMAX(1,1) models on a rolling basis, using the past 36 months to predict the return and its sign of the following month. This will enable us to calculate average performance measures such as RMSE, MAPE, or accuracy (in predicting the correct return sign) for each of the models (Base, MCSI, Sentiment, MCSI + Sentiment, called after the set of included exo vars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             returns      msci  sentiment  msci_lag1  sentiment_lag1\n",
      "Date                                                                \n",
      "2012-02-01  0.146806  0.011673   0.148969   0.198444       -0.008786\n",
      "2012-03-01  0.083715  0.035019  -0.140396   0.011673        0.148969\n",
      "2012-04-01  0.001341  0.007782  -0.019119   0.035019       -0.140396\n",
      "2012-05-01 -0.047849  0.112840  -0.070178   0.007782       -0.019119\n",
      "2012-06-01 -0.005572 -0.237354   0.241201   0.112840       -0.070178\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"./tsdata/modeldata.csv\", index_col='Date', parse_dates=True)\n",
    "df.index.freq = \"MS\"\n",
    "df['msci_lag1'] = df['msci'].shift(1)\n",
    "df['sentiment_lag1'] = df['sentiment'].shift(1)\n",
    "df = df.dropna()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Average MAPE</th>\n",
       "      <th>Average RMSE</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>Correct Sign Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>138.083023</td>\n",
       "      <td>0.059705</td>\n",
       "      <td>-92.833047</td>\n",
       "      <td>-88.082490</td>\n",
       "      <td>0.56383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Both</td>\n",
       "      <td>139.926247</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>-90.445959</td>\n",
       "      <td>-82.528364</td>\n",
       "      <td>0.595745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSCI</td>\n",
       "      <td>132.120311</td>\n",
       "      <td>0.059778</td>\n",
       "      <td>-91.492446</td>\n",
       "      <td>-85.158370</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentiment</td>\n",
       "      <td>142.347203</td>\n",
       "      <td>0.059677</td>\n",
       "      <td>-91.662310</td>\n",
       "      <td>-85.328234</td>\n",
       "      <td>0.62766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Average MAPE  Average RMSE        AIC        BIC  \\\n",
       "0       Base    138.083023      0.059705 -92.833047 -88.082490   \n",
       "1       Both    139.926247      0.059814 -90.445959 -82.528364   \n",
       "2       MSCI    132.120311      0.059778 -91.492446 -85.158370   \n",
       "3  Sentiment    142.347203      0.059677 -91.662310 -85.328234   \n",
       "\n",
       "  Correct Sign Percentage  \n",
       "0                 0.56383  \n",
       "1                0.595745  \n",
       "2                0.553191  \n",
       "3                 0.62766  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mape(actual, pred):\n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / actual)) * 100\n",
    "\n",
    "def rmse(actual, pred):\n",
    "    return np.sqrt(mean_squared_error(actual, pred))\n",
    "\n",
    "results = pd.DataFrame(columns=['Date', 'Model', 'MAPE', 'RMSE', 'Correct Sign', 'AIC', 'BIC'])\n",
    "\n",
    "window_size = 36\n",
    "\n",
    "#loop over each time window, starting at index 36 up to the second last value of the df\n",
    "for i in range(window_size, len(df) - 1):\n",
    "    #select the training data set reaching from (i - window size) to i (e.g. i = 36; reaching from index 0 to 36)\n",
    "    train = df.iloc[i - window_size:i]\n",
    "    #select the test data set satarting with the first value after the training window\n",
    "    test = df.iloc[i:i+1]\n",
    "    \n",
    "    #build data sets\n",
    "    y_train = train['returns']\n",
    "    y_test = test['returns']\n",
    "\n",
    "    X_msci_train = train[[\"msci_lag1\"]]\n",
    "    X_sent_train = train[[\"sentiment_lag1\"]]\n",
    "    X_both_train = train[[\"msci_lag1\", \"sentiment_lag1\"]]\n",
    "\n",
    "    X_msci_test = test[[\"msci_lag1\"]]\n",
    "    X_sent_test = test[[\"sentiment_lag1\"]]\n",
    "    X_both_test = test[[\"msci_lag1\", \"sentiment_lag1\"]]\n",
    "\n",
    "    #specify models\n",
    "    models = {'Base': (y_train, None),\n",
    "              'MSCI': (y_train, X_msci_train),\n",
    "              'Sentiment': (y_train, X_sent_train),\n",
    "              'Both': (y_train, X_both_train)}\n",
    "    test_exog = {'Base': None, 'MSCI': X_msci_test, 'Sentiment': X_sent_test, 'Both': X_both_test}\n",
    "\n",
    "    #for each of the above selected data sets for each i in the window size, loop over each of the models\n",
    "    for model_name, (y, X) in models.items():\n",
    "        #specify AMRA(1,1) model\n",
    "        model = SARIMAX(y, X, order=(1, 0, 1), enforce_stationarity=True, enforce_invertibility=True)\n",
    "        #fit model to the data\n",
    "        fitted_model = model.fit(disp=False, maxiter=300)\n",
    "        #predict\n",
    "        prediction = fitted_model.get_forecast(steps=1, exog=test_exog[model_name]).predicted_mean\n",
    "        #calculate measuers, MAPE, RMSE, and the sum of correct sign detechtion\n",
    "        mape_score = mape(y_test.values, prediction.values)\n",
    "        rmse_score = rmse(y_test.values, prediction.values)\n",
    "        correct_sign = (np.sign(y_test.values) == np.sign(prediction.values)).astype(int)\n",
    "\n",
    "        #Create a performance data frame where resutls for each models are stored\n",
    "        new_row = pd.DataFrame({\n",
    "            'Date': [test.index[0]],\n",
    "            'Model': [model_name],\n",
    "            'MAPE': [mape_score],\n",
    "            'RMSE': [rmse_score],\n",
    "            'Correct Sign': [correct_sign[0]],\n",
    "            'AIC': [fitted_model.aic],\n",
    "            'BIC': [fitted_model.bic]\n",
    "        })\n",
    "        results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "#Calculate the average performance measures for each model\n",
    "average_metrics = results.groupby('Model').agg({\n",
    "    'MAPE': 'mean',\n",
    "    'RMSE': 'mean',\n",
    "    'AIC': 'mean',\n",
    "    'BIC': 'mean',\n",
    "    'Correct Sign': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "average_metrics.rename(columns={\n",
    "    'MAPE': 'Average MAPE',\n",
    "    'RMSE': 'Average RMSE',\n",
    "    'Correct Sign': 'Correct Sign Percentage'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "average_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that ARMAX (1,1) models with our own sentiment score perform on average best in terms of RMSE and of accuracy of predicting the correct return sign."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('tf_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37d77ca2ec854fb92fac4ea47a33e5e456752ae25f8d23e6c8345a2d53411d89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
