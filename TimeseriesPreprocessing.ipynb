{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script performs data cleaning for various exogenous variables (GDP growth, CPI growth, Unemployment rate, Michigan Sentiment Consumer Index (MSCI)) and builds the dependent variable (log-returns of a equity portfolio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  3 of 3 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "import pickle\n",
    "import yfinance as yf\n",
    "import pandas_datareader.data as pdr\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "tickers = ['AAPL', 'MSI', 'GOOGL']\n",
    "\n",
    "price_data = yf.download(tickers, start='2011-11-01', end='2022-12-31', interval='1mo')['Close']\n",
    "\n",
    "#we have to download the data separately for Samsung as it is not in US prices:\n",
    "samsung_data = yf.download('005930.KS', start='2011-11-01', end='2022-12-31', interval='1mo')['Close']\n",
    "\n",
    "#fetching usd/krw historical exchange rate to convert samsung KWR stock price to USD stock price\n",
    "exchange_rates = pdr.DataReader('DEXKOUS', 'fred', start='2011-11-01', end='2022-12-31')\n",
    "exchange_rates = exchange_rates.resample('1ME').ffill().reindex(samsung_data.index, method='nearest')\n",
    "price_data['SAMS'] = samsung_data / exchange_rates['DEXKOUS']\n",
    "order = ['AAPL', 'SAMS', 'GOOGL', 'MSI']\n",
    "price_data = price_data[order]\n",
    "\n",
    "\n",
    "\n",
    "weights = [0.6823, 0.2520, 0.0390, 0.0267]\n",
    "weighted_prices = price_data.multiply(weights, axis='columns')\n",
    "portfolio_value = weighted_prices.sum(axis=1)\n",
    "portfolio_value.to_csv('./tsdata/portfolio.csv', index=True)\n",
    "log_returns = np.log(portfolio_value / portfolio_value.shift(1)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessMichiganSentiment:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def preprocess(self):\n",
    "        self.data[\"Date\"] = pd.to_datetime(self.data[\"YYYY\"].astype(str) + '-' + self.data[\"Month\"], format='%Y-%B')\n",
    "        self.data = self.data.sort_values(\"Date\")\n",
    "        self.data = self.data[(self.data[\"Date\"] >= '2011-12-01') & (self.data[\"Date\"] <= '2022-12-31')]\n",
    "        self.data = self.data.groupby(self.data[\"Date\"].dt.to_period(\"M\")).last()\n",
    "        self.data.reset_index(drop=True, inplace=True)\n",
    "        self.data.drop(columns=['Month', 'YYYY'], inplace=True)\n",
    "\n",
    "        self.data['Date'] = pd.to_datetime(self.data['Date'])\n",
    "        self.data.set_index('Date', inplace=True)\n",
    "        return self.data\n",
    "\n",
    "\n",
    "\n",
    "michigansentiment = pd.read_csv(\"./tsdata/michigansentiment.csv\")\n",
    "michigansentiment_preprocessed = PreprocessMichiganSentiment(michigansentiment)\n",
    "michigansentiment = michigansentiment_preprocessed.preprocess()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load sentiment scores\n",
    "sentiment = pd.read_csv(\"./Sentiment_data/sentiment_scores.csv\").drop([\"Unnamed: 0\"], axis=1)\n",
    "len(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeriodIndex([], dtype='period[M]')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if sentiment scores are complete\n",
    "pd.set_option('display.max_rows', None)\n",
    "data = pd.DataFrame()\n",
    "data[\"month\"] = sentiment[\"month\"]\n",
    "expected_months = pd.period_range(start='2012-01', end='2022-12', freq='M')\n",
    "data['month'] = data['month'].astype(str).apply(lambda x: pd.Period(year=int(x[:4]), month=int(x[4:]), freq='M'))\n",
    "missing_months = expected_months[~expected_months.isin(data['month'])]\n",
    "missing_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have to add one additional row to the sentiment data frame to match the index. However, the artificial score will be disregarded later.\n",
    "new_row = pd.DataFrame({\n",
    "    \"month\": [201112],\n",
    "    \"scaled_scores\": [sentiment[\"scaled_scores\"].mean()]\n",
    "})\n",
    "\n",
    "sentiment = pd.concat([new_row, sentiment], ignore_index=True)\n",
    "len(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create final data frame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df.index = log_returns.index\n",
    "\n",
    "df[\"returns\"] = log_returns.values\n",
    "#df[\"gdpgrowth\"] = gdpgrowth[\"Monthly Real GDP Index\"].values\n",
    "#df[\"cpigrowth\"] = cpigrowth[\"USACPALTT01CTGYM\"].values\n",
    "#df[\"unemp\"] = unemploymentrate[\"UNRATE\"].values\n",
    "df[\"msci\"] = michigansentiment[\"ICS_ALL\"].values\n",
    "df[\"sentiment\"] = sentiment[\"scaled_scores\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_msci = MinMaxScaler(feature_range = (-1, 1))\n",
    "df[[\"msci\"]] = scaler_msci.fit_transform(df[[\"msci\"]])\n",
    "df.to_csv('./tsdata/preprocessed_data.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.1 ('saleseq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33e514ddd44e070d440c6cf047af6a4d4e83e2b8cc52aa796edd887a6d6b5d7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
